{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN29kCo10bgdRZ+PHyulxzD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kanishkbehl/IMAGE-VIDEO-AUDIO-PROCESSING/blob/main/IMAGE%2C_VIDEO%2C_AUDIO_PROCESSING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMAGES"
      ],
      "metadata": {
        "id": "84jlOEjngIEI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CROPPING** **TOOL**"
      ],
      "metadata": {
        "id": "XETgLdmfcuWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "flag = False\n",
        "ix = -1\n",
        "iy = -1\n",
        "\n",
        "img = cv2.imread(\"sample.jpg\")\n",
        "def crop(event,x,y,flags,params):\n",
        "    global flag, ix, iy\n",
        "    if event == 1:\n",
        "        flag = True\n",
        "        ix = x\n",
        "        iy = y\n",
        "\n",
        "    elif event == 4:\n",
        "\n",
        "        fx=x\n",
        "        fy=y\n",
        "\n",
        "        flag = False\n",
        "        cv2.rectangle(img, pt1=(ix,iy),pt2=(x,y), color=(0,0,0), thickness=1)\n",
        "\n",
        "        cropped= img[iy:fy,ix:fx]\n",
        "        cv2.imshow(\"new_window\",cropped)\n",
        "        cv2.waitKey(0)\n",
        "\n",
        "cv2.namedWindow(winname=\"window\")\n",
        "cv2.setMouseCallback(\"window\",crop)\n",
        "\n",
        "\n",
        "while True:\n",
        "    cv2.imshow(\"window\",img)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord(\"x\"):\n",
        "        break\n",
        "\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "mitca-EEcoQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DRAWING SHAPES**"
      ],
      "metadata": {
        "id": "5Bkb8eYJc7m5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "img = np.zeros((512,512,3)) #IT IS USED TO CREATE A BLACK BLANK IMAGE\n",
        "\n",
        "#RECTANGLE\n",
        "cv2.rectangle(img,pt1=(100,100),pt2=(300,300),color=(255,0,0), thickness=3)\n",
        "cv2.imshow(\"window\",img)    #SHOW THE IMAGE\n",
        "cv2.waitKey(0)              #SO THAT IT WAITS ON THE WINDOW\n",
        "\n",
        "cv2.rectangle(img,pt1=(100,100),pt2=(300,300),color=(255,0,0), thickness=-1)\n",
        "#IF WE PUT THICKNESS -1 THAT MEANS TO FILL THE SHAPE FULLY\n",
        "cv2.imshow(\"window\",img)    #SHOW THE IMAGE\n",
        "cv2.waitKey(0)              #SO THAT IT WAITS ON THE WINDOW\n",
        "\n",
        "#CIRCLE\n",
        "cv2.circle(img, center=(100,400), radius=50, color=(0,0,255), thickness=3)\n",
        "cv2.imshow(\"window\",img)    #SHOW THE IMAGE\n",
        "cv2.waitKey(0)              #SO THAT IT WAITS ON THE WINDOW\n",
        "\n",
        "#LINE\n",
        "cv2.line(img, pt1=(200,250), pt2=(300,400), color=(0,255,0),thickness=3)\n",
        "cv2.imshow(\"window\",img)    #SHOW THE IMAGE\n",
        "cv2.waitKey(0)              #SO THAT IT WAITS ON THE WINDOW\n",
        "\n",
        "#TEXT\n",
        "cv2.putText(img, text=\"HELLO\", org=(100,100), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=4, color=(255,0,255), thickness=3)\n",
        "cv2.imshow(\"window\",img)    #SHOW THE IMAGE\n",
        "cv2.waitKey(0)              #SO THAT IT WAITS ON THE WINDOW"
      ],
      "metadata": {
        "id": "AEXVeD3vc6oZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMAGE FLIP**"
      ],
      "metadata": {
        "id": "U8v9VLtNdJbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as num\n",
        "\n",
        "img = cv2.imread(\"sample.jpg\")\n",
        "\n",
        "img_flip = cv2.flip(img,0)      #FLIP ON VERTICAL AXIS\n",
        "cv2.imshow(\"window\",img_flip)    #SHOW THE IMAGE\n",
        "cv2.waitKey(0)              #SO THAT IT WAITS ON THE WINDOW\n",
        "\n",
        "img_flip = cv2.flip(img,1)      #FLIP ON HORIZONTAL AXIS\n",
        "cv2.imshow(\"window\",img_flip)    #SHOW THE IMAGE\n",
        "cv2.waitKey(0)              #SO THAT IT WAITS ON THE WINDOW\n",
        "\n",
        "img_flip = cv2.flip(img,-1)     #FLIP ON BOTH HORIZONTAL AND VERTICAL\n",
        "cv2.imshow(\"window\",img_flip)    #SHOW THE IMAGE\n",
        "cv2.waitKey(0)              #SO THAT IT WAITS ON THE WINDOW"
      ],
      "metadata": {
        "id": "eaFrfi1sdD_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMAGE RESIZE WITH NUMBER**"
      ],
      "metadata": {
        "id": "v6_cOeKcdSgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "img = cv2.imread(\"sample.jpg\")\n",
        "img_resize = cv2.resize(img,(256,256))\n",
        "\n",
        "print(img_resize.shape)         #SIZE OF RESIZED IMAGE FOR CONFIRMATION\n",
        "\n",
        "cv2.imshow(\"window\",img_resize) #SHOW THE IMAGE\n",
        "cv2.waitKey(0)                  #SO THAT IT WAITS ON THE WINDOW\n",
        "\n"
      ],
      "metadata": {
        "id": "As6cOcfhdN36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMAGE RESIZE WITH PERCENTAGE**"
      ],
      "metadata": {
        "id": "13VuTWRLda3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "img = cv2.imread(\"sample.jpg\")\n",
        "# FOR KNOWLEDGE\n",
        "# height = img.shape[0]\n",
        "# width = img.shape[1]\n",
        "# channels = img.shape[2]\n",
        "\n",
        "img_resize = cv2.resize(img, (img.shape[1]//2, img.shape[0]//2)) # REDUCING BOTH WIDTH AND HEIGHT BY 50%\n",
        "\n",
        "print(img_resize.shape)  # SIZE OF RESIZED IMAGE FOR CONFIRMATION\n",
        "\n",
        "cv2.imshow(\"window\", img_resize)  # SHOW THE IMAGE\n",
        "cv2.waitKey(0)  # SO THAT IT WAITS ON THE WINDOW\n"
      ],
      "metadata": {
        "id": "3tD4EMymdW0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**COLOURED IMAGE TO GRAYSCALE IMAGE**"
      ],
      "metadata": {
        "id": "Sb-FBO4OdkV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as num\n",
        "\n",
        "img = cv2.imread(\"sample.jpg\")\n",
        "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "cv2.imshow(\"window\",img_gray)        #SHOW GRAYSCALE IMAGE\n",
        "cv2.waitKey(0)\n",
        "print(img_gray.shape)               #SHAPE OF IMAGE"
      ],
      "metadata": {
        "id": "pW7fMp9odjkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**REMOVING A COLOUR FROM IMAGE**"
      ],
      "metadata": {
        "id": "9wEKk3Bid0a5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as num\n",
        "\n",
        "img = cv2.imread(\"sample.jpg\")\n",
        "\n",
        "\n",
        "img[:,:,0]=0             #THIS MEANS THAT BLUE COLOUR WILL BE REMOVED\n",
        "cv2.imshow(\"window\",img) #SHOW THE IMAGE\n",
        "cv2.waitKey(0)              #SO THAT IT WAITS ON THE WINDOW\n",
        "\n",
        "img[:,:,1]=0            #THIS MEANS THAT GREEN COLOUR WILL BE REMOVED\n",
        "cv2.imshow(\"window\",img) #SHOW THE IMAGE\n",
        "cv2.waitKey(0)              #SO THAT IT WAITS ON THE WINDOW\n",
        "\n",
        "img[:,:,2]=0             #THIS MEANS THAT RED COLOUR WILL BE REMOVED\n",
        "cv2.imshow(\"window\",img) #SHOW THE IMAGE\n",
        "cv2.waitKey(0)              #SO THAT IT WAITS ON THE WINDOW"
      ],
      "metadata": {
        "id": "78A0YtSndzrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SAVING A CROPPED IMAGE**"
      ],
      "metadata": {
        "id": "l1gm8oCceXBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as num\n",
        "\n",
        "img = cv2.imread(\"sample.jpg\")\n",
        "\n",
        "img_crop = img[300:700,100:300]  #HEIGHT , WIDTH\n",
        "\n",
        "cv2.imwrite(\"CROPPED IMAGE.png\", img_crop)        #SAVE AN IMAGE\n",
        "cv2.imshow(\"window\",img_crop) #SHOW THE IMAGE\n",
        "cv2.waitKey(0)              #SO THAT IT WAITS ON THE WINDOW"
      ],
      "metadata": {
        "id": "2MfDyxF5eWZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SHOW IMAGE**"
      ],
      "metadata": {
        "id": "YE5qN2u1f7rI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as num\n",
        "\n",
        "img = cv2.imread(\"sample.jpg\")\n",
        "print(type(img))        #TYPE OF IMAGE\n",
        "print(img.shape)        #SHAPE OF IMAGE\n",
        "\n",
        "cv2.imshow(\"window\",img) #SHOW THE IMAGE\n",
        "cv2.waitKey(0)              #SO THAT IT WAITS ON THE WINDOW"
      ],
      "metadata": {
        "id": "7-yMyDmJf7Ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STACKING IMAGES**"
      ],
      "metadata": {
        "id": "2vzfZcKcgBuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "img = cv2.imread(\"sample.jpg\")\n",
        "\n",
        "imgBlue = img[:,:,0]\n",
        "imgGreen = img[:,:,1]\n",
        "imgRed = img[:,:,2]\n",
        "\n",
        "new_img = np.hstack((imgBlue, imgGreen, imgRed))\n",
        "\n",
        "cv2.imshow(\"window\",new_img)     #SHOW THE IMAGE\n",
        "cv2.waitKey(0)                   #SO THAT IT WAITS ON THE WINDOW\n"
      ],
      "metadata": {
        "id": "T1osUtmegApZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VIDEO"
      ],
      "metadata": {
        "id": "GYWuqDJkialJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**COLOURED VIDEO TO GRAYSCALE**"
      ],
      "metadata": {
        "id": "3x1Oe_ymiiaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "cap = cv2.VideoCapture(\"sample.mp4\")\n",
        "\n",
        "while True:\n",
        "    ret , frame = cap.read()\n",
        "\n",
        "    img_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    cv2.imshow(\"window\",img_gray)\n",
        "\n",
        "    if cv2.waitKey(1)  &  0xFF == ord(\"x\"):\n",
        "        break\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "\n"
      ],
      "metadata": {
        "id": "43uHJDxjiezl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SHOW VIDEO**"
      ],
      "metadata": {
        "id": "CYfJHPYCiq7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "cap = cv2.VideoCapture(\"sample.mp4\")\n",
        "\n",
        "while True:\n",
        "    ret , frame = cap.read()\n",
        "\n",
        "    cv2.imshow(\"webcam\",frame)\n",
        "\n",
        "    if cv2.waitKey(1)  &  0xFF == ord(\"x\"):\n",
        "        break\n",
        "\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "xOmeVTrVingW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AUDIO\n"
      ],
      "metadata": {
        "id": "FewmkoLCjpBR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AUDIO TO TEXT CONVERSION**"
      ],
      "metadata": {
        "id": "ZkjiRXeGjtKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-D2Xm8INjwjj",
        "outputId": "99837ac2-6cf1-412c-c908-958b7ad43823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.10.0-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2023.7.22)\n",
            "Installing collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import speech_recognition as sr\n",
        "\n",
        "r = sr.Recognizer()\n",
        "\n",
        "with sr.AudioFile('Sample.wav') as source:\n",
        "    audio_text = r.listen(source,phrase_time_limit=100)\n",
        "\n",
        "    try:\n",
        "        # using google speech recognition\n",
        "        text = r.recognize_google(audio_text)\n",
        "        print('Converting audio transcripts into text ...')\n",
        "        print(text)\n",
        "    except:\n",
        "         print('Sorry.. run again...')"
      ],
      "metadata": {
        "id": "bypbo2HrkNns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMAGE TO TEXT CONVERSION**"
      ],
      "metadata": {
        "id": "aao1YIo9kVhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "!pip install Pillow==9.0.0"
      ],
      "metadata": {
        "id": "XzE8-GZ-kepz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "YjNVzZbVkiqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "mDelt3A3kmGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extractedInformation = pytesseract.image_to_string(Image.open('/content/test2.png'))"
      ],
      "metadata": {
        "id": "HVZQGs4Ckrdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(extractedInformation)"
      ],
      "metadata": {
        "id": "8V_rVBsYktEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMAGE TO TEXT TO AUDIO CONVERSION**"
      ],
      "metadata": {
        "id": "J1E--uFrkzDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract\n",
        "from PIL import Image\n",
        "import pygame\n",
        "import gtts\n",
        "#import pyttsx3\n",
        "#from googletrans import Translator"
      ],
      "metadata": {
        "id": "POhsMopbk4nP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open('/content/Picture1.png')\n",
        "print(img)"
      ],
      "metadata": {
        "id": "xsVa9d0Ok8SX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = pytesseract.image_to_string(Image.open('/content/Picture1.png'))\n",
        "print(result)\n",
        "tts = gtts.gTTS(result)\n",
        "tts.save(\"hello.mp3\")"
      ],
      "metadata": {
        "id": "w5afEmdJk-Nj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SPEECH RECOGNIZER**"
      ],
      "metadata": {
        "id": "G6AOZ4iclI06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install SpeechRecognition pydub"
      ],
      "metadata": {
        "id": "jflpSyfAlAAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import speech_recognition as sr\n",
        "import os\n",
        "import subprocess\n",
        "from google.colab import files\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence"
      ],
      "metadata": {
        "id": "RnyZg39flPrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.upload()"
      ],
      "metadata": {
        "id": "NrKE_hb5lRvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert mp3 to wav file\n",
        "subprocess.call(['ffmpeg', '-i', '01.mp3','wav_file.wav'])"
      ],
      "metadata": {
        "id": "DG5TZyRKlUus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the recognizer\n",
        "r = sr.Recognizer()\n",
        "\n",
        "# a function that splits the audio file into chunks\n",
        "# and applies speech recognition\n",
        "\n",
        "def get_large_audio_transcription(path):\n",
        "    \"\"\"\n",
        "    Splitting the large audio file into chunks\n",
        "    and apply speech recognition on each of these chunks\n",
        "    \"\"\"\n",
        "    # open the audio file using pydub\n",
        "    sound = AudioSegment.from_wav(path)\n",
        "    # split audio sound where silence is 700 miliseconds or more and get chunks\n",
        "    chunks = split_on_silence(sound,\n",
        "        # experiment with this value for your target audio file\n",
        "        min_silence_len = 500,\n",
        "        # adjust this per requirement\n",
        "        silence_thresh = sound.dBFS-14,\n",
        "        # keep the silence for 1 second, adjustable as well\n",
        "        keep_silence=500,\n",
        "    )\n",
        "    folder_name = \"audio-chunks\"\n",
        "    # create a directory to store the audio chunks\n",
        "    if not os.path.isdir(folder_name):\n",
        "        os.mkdir(folder_name)\n",
        "    whole_text = \"\"\n",
        "    # process each chunk\n",
        "    for i, audio_chunk in enumerate(chunks, start=1):\n",
        "        # export audio chunk and save it in\n",
        "        # the `folder_name` directory.\n",
        "        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
        "        audio_chunk.export(chunk_filename, format=\"wav\")\n",
        "        # recognize the chunk\n",
        "        with sr.AudioFile(chunk_filename) as source:\n",
        "            audio_listened = r.record(source)\n",
        "            # try converting it to text\n",
        "            try:\n",
        "                text = r.recognize_google(audio_listened)\n",
        "            except sr.UnknownValueError as e:\n",
        "                print(\"Error:\", str(e))\n",
        "            else:\n",
        "                text = f\"{text.capitalize()}. \"\n",
        "                print(chunk_filename, \":\", text)\n",
        "                whole_text += text\n",
        "    # return the text for all chunks detected\n",
        "    return whole_text"
      ],
      "metadata": {
        "id": "PBTnbfdQlXQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/wav_file.wav\"\n",
        "print(\"\\nFull text:\", get_large_audio_transcription(path))"
      ],
      "metadata": {
        "id": "5QJpxHM_la0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VIDEO TO AUDIO CONVERSION**"
      ],
      "metadata": {
        "id": "lQcZ3gZNlfrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install moviepy"
      ],
      "metadata": {
        "id": "uSshNCnwljSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "import os\n",
        "def convert_video_to_audio_moviepy(video_file, output_ext=\"mp3\"):\n",
        "    \"\"\"Converts video to audio using MoviePy library\n",
        "    that uses `ffmpeg` under the hood\"\"\"\n",
        "    filename, ext = os.path.splitext(video_file)\n",
        "    clip = VideoFileClip(video_file)\n",
        "    clip.audio.write_audiofile(f\"{filename}.{output_ext}\")"
      ],
      "metadata": {
        "id": "eID7idbrllo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert_video_to_audio_moviepy('/content/test.mp4')"
      ],
      "metadata": {
        "id": "SXg2C5L5loOF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}